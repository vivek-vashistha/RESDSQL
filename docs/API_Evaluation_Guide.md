# API Evaluation Script Guide

## Overview
The `evaluate_api_with_golden_results.py` script evaluates SQL queries generated by the API against golden (expected) results from the Spider2 dataset.

## How to Run

### Basic Usage
```bash
python utils/evaluate_api_with_golden_results.py \
    --input data/spider2/converted/spider2-lite_new_format.json \
    --output data/spider2/converted/spider2-lite_api_evaluated.json \
    --limit 5
```

### Common Arguments
- `--input`: Path to input JSON file with questions (default: `data/spider2/converted/spider2-lite_new_format.json`)
- `--output`: Path to output JSON file with results (default: `data/spider2/converted/spider2-lite_api_evaluated.json`)
- `--api_url`: API endpoint URL (default: `http://localhost:8000/infer`)
- `--limit`: Process only first N entries (useful for testing)
- `--api_timeout`: API request timeout in seconds (default: 600 = 10 minutes)

### Example: Test with 5 entries
```bash
python utils/evaluate_api_with_golden_results.py \
    --input data/spider2/converted/spider2-lite_new_format.json \
    --output data/spider2/converted/spider2-lite_api_evaluated.json \
    --limit 5 \
    --api_url http://localhost:8000/infer
```

## How It Works

### Step 1: Load and Filter Data
- Loads the input JSON file containing questions
- Filters entries where `gold_sql_available: true`
- Applies `--limit` if specified (for testing)

### Step 2: Call API
- Sends each question to the API endpoint
- API generates SQL query from the question
- Receives response with generated SQL
- Logs full API response (SQL, execution status, errors)

### Step 3: Execute SQL
- Takes the SQL query from API response
- Connects to SQLite database (located in `./database/{db_id}/{db_id}.sqlite`)
- Executes SQL query using `pd.read_sql_query()`
- Returns results as pandas DataFrame
- Saves execution results to CSV file in `./data/spider2/execution_results/`

**SQL Execution Details:**
- Uses SQLite3 to connect to database
- Creates in-memory copy of database for safe execution
- Executes query and converts results to DataFrame
- Handles errors gracefully (logs and continues)

### Step 4: Compare with Golden Results
- Finds golden CSV files for the instance (handles `_a`, `_b`, `_c` variants)
- Loads golden CSV files
- Compares execution results with golden results using pandas DataFrame comparison
- Supports:
  - Multiple golden file variants (if question has multiple valid answers)
  - Condition columns (for partial matching)
  - Ignoring row order (if specified in metadata)
- Logs detailed comparison results

### Step 5: Save Results
- Saves complete results to JSON file (includes API response, SQL, execution results, comparison)
- Saves statistics to separate `_statistics.json` file
- Prints summary statistics to console

## Output Files

### Main Results JSON
Contains for each entry:
- Original question and metadata
- API response (full JSON)
- Generated SQL
- Execution results (as list of dictionaries)
- CSV filename of execution results
- Golden comparison results (match status, details)

### Statistics JSON
Contains summary:
- Total entries processed
- API success/failure counts
- SQL execution success/failure counts
- Golden file found/not found counts
- Overall accuracy percentage

### Execution Results CSV
- One CSV file per entry in `./data/spider2/execution_results/`
- Named as `{instance_id}.csv`
- Contains actual query results

## Comparison Logic

The script compares DataFrames using:
- **Column matching**: Checks if all columns from golden file exist in execution results
- **Row matching**: Checks if all rows from golden file exist in execution results
- **Tolerance**: Uses 0.01 tolerance for floating-point comparisons
- **Order**: Can ignore row order if specified in metadata
- **Multiple variants**: If multiple golden files exist, matches if execution results match ANY variant

## Error Handling

The script handles:
- **API failures**: Logs error, marks as failed, continues
- **SQL execution errors**: Logs SQLite error, marks as failed, continues
- **Missing databases**: Logs error, marks as failed, continues
- **Missing golden files**: Logs warning, marks as not found, continues
- **Comparison errors**: Logs error with traceback, marks as incorrect, continues

## Logging

The script provides detailed logging:
- API call status and duration
- SQL being executed
- Execution results (shape, columns, first row)
- Comparison details (shapes, columns, match status)
- Errors with full tracebacks

## Requirements

- Python 3.8+
- pandas
- requests
- sqlite3 (built-in)
- tqdm

## Notes

- Only processes entries with `gold_sql_available: true`
- Uses SQLite databases (not BigQuery or Snowflake)
- API must be running and accessible at the specified URL
- Database files must exist in `./database/{db_id}/` directory
- Golden CSV files must exist in the specified gold result directory
